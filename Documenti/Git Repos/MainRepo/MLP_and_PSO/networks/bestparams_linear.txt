Number of layers:3
Network size:[4, 4, 1]
Input count:1
Neurons:  layer 0
    neuron 0
    w:[-3.1354605]
    b:1.33476935201
    a:<function act_sigmoid at 0x7fb70433cde8>
    neuron 1
    w:[1.93321073]
    b:3.4629874012
    a:<function act_sigmoid at 0x7fb70433cde8>
    neuron 2
    w:[2.2665688]
    b:-3.23464464274
    a:<function act_sigmoid at 0x7fb70433cde8>
    neuron 3
    w:[3.99590215]
    b:6.55649958221
    a:<function act_sigmoid at 0x7fb70433cde8>
  layer 1
    neuron 0
    w:[ 2.02427668 -3.68998255  3.69731845  1.13245455]
    b:2.90342640396
    a:<function act_tanh at 0x7fb70433ced8>
    neuron 1
    w:[-2.15834292 -5.50754921  0.09835842  0.57542541]
    b:-3.30572520498
    a:<function act_sigmoid at 0x7fb70433cde8>
    neuron 2
    w:[ 0.36382106 -3.01253935 -2.12786252 -1.08335506]
    b:3.74799178186
    a:<function act_tanh at 0x7fb70433ced8>
    neuron 3
    w:[-0.18616871  0.84409553  0.67956756  0.76989724]
    b:-1.94336066812
    a:<function act_sigmoid at 0x7fb70433cde8>
  layer 2
    neuron 0
    w:[ 4.8916955  -0.74553527 -2.11347379  2.06456127]
    b:-0.956769560217
    a:<function act_cos at 0x7fb70433cf50>
Fitness of Network: -6.17978670321e-05