Number of layers:3
Network size:[4, 4, 1]
Input count:2
Neurons:  layer 0
    neuron 0
    w:[-5.12652946  4.48625932]
    b:3.84829996786
    a:<function act_tanh at 0x7f990b832ed8>
    neuron 1
    w:[ 2.84419064 -0.52980025]
    b:2.28142282746
    a:<function act_tanh at 0x7f990b832ed8>
    neuron 2
    w:[-1.50074682 -5.19574563]
    b:-4.07769480315
    a:<function act_sigmoid at 0x7f990b832de8>
    neuron 3
    w:[ 2.14352387 -2.19547454]
    b:0.823329098417
    a:<function act_sigmoid at 0x7f990b832de8>
  layer 1
    neuron 0
    w:[-6.00629826  3.27371364  1.19656009  5.37561884]
    b:0.295438664671
    a:<function act_sigmoid at 0x7f990b832de8>
    neuron 1
    w:[-0.50006249  4.76675289 -2.70079506  3.15090668]
    b:-0.569141411838
    a:<function act_sigmoid at 0x7f990b832de8>
    neuron 2
    w:[-2.44247061 -3.35057307 -2.9721002   3.06012922]
    b:-5.53330250136
    a:<function act_tanh at 0x7f990b832ed8>
    neuron 3
    w:[-1.40645472  1.71232844 -2.3046408   5.00209275]
    b:-5.81759274755
    a:<function act_sigmoid at 0x7f990b832de8>
  layer 2
    neuron 0
    w:[ 3.04535671 -3.52965748  0.22973334 -2.87181009]
    b:-3.0219151703
    a:<function act_cos at 0x7f990b832f50>
Fitness of Network: -8.83735423747e-06